{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84d668b-6ee0-4594-b797-0324161de6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read: Arogya.jpg\n",
      "File read: Benedict.jpg\n",
      "Starting facial recognition. Press 'q' to exit.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n",
      "No faces detected in the frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_faces(face_dir):\n",
    "    face_encodings = []\n",
    "    face_labels = []\n",
    "    for file in os.listdir(face_dir):\n",
    "        if file.lower().endswith((\".jpg\", \".png\")):\n",
    "            path = os.path.join(face_dir, file)\n",
    "            img = face_recognition.load_image_file(path)\n",
    "            encodings = face_recognition.face_encodings(img)\n",
    "            if encodings:\n",
    "                face_encodings.append(encodings[0])\n",
    "                face_labels.append(os.path.splitext(file)[0])\n",
    "    return face_encodings, face_labels\n",
    "\n",
    "def webcam_face_recognition(encodings, labels):\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if not cam.isOpened():\n",
    "        return\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        locations = face_recognition.face_locations(rgb_frame)\n",
    "        if locations:\n",
    "            faces_in_frame = face_recognition.face_encodings(rgb_frame, locations)\n",
    "            for (top, right, bottom, left), face_enc in zip(locations, faces_in_frame):\n",
    "                matches = face_recognition.compare_faces(encodings, face_enc)\n",
    "                label = \"Unknown\"\n",
    "                distances = face_recognition.face_distance(encodings, face_enc)\n",
    "                best_match = np.argmin(distances)\n",
    "                if matches[best_match]:\n",
    "                    label = labels[best_match]\n",
    "                    similarity = (1 - distances[best_match]) * 100\n",
    "                    label += f\" ({similarity:.2f}%)\"\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "faces_dir = r\"C:\\Users\\Arogya Mary\\Downloads\\imaging\"\n",
    "face_encodings, face_labels = load_faces(faces_dir)\n",
    "webcam_face_recognition(face_encodings, face_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c85511-e4dc-4105-98f1-67278d15649d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
